{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import importlib\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "import module\n",
    "\n",
    "try:\n",
    "    importlib.reload(module) # reload module\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    importlib.reload(config) # reload config\n",
    "except NameError:\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df already exist\n",
      "(352073, 14)\n"
     ]
    }
   ],
   "source": [
    "# if df is not loaded, load df\n",
    "if not \"df_ori\" in locals():\n",
    "    path = config.path / \"raw\"\n",
    "\n",
    "    # if data is in one file\n",
    "    if config.is_mutiple_files == False:\n",
    "        if config.has_headers:\n",
    "            df_ori = pd.read_excel(path, skiprows=2)\n",
    "        else:\n",
    "            df_ori = pd.read_excel(path)\n",
    "\n",
    "    # if data is in multiple files (data from coco must have headers)\n",
    "    else:\n",
    "        all_files = glob.glob(os.path.join(path, \"*.xlsx\"))\n",
    "\n",
    "        li = []\n",
    "        for filename in all_files:\n",
    "            df = pd.read_excel(filename, index_col=None, skiprows=2)\n",
    "            li.append(df)\n",
    "        df_ori = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "    print(\"df loaded\")\n",
    "\n",
    "# if df is loaded, do not load again\n",
    "else:\n",
    "    print(\"df already exist\")\n",
    "\n",
    "df = df_ori.copy()\n",
    "print(df.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF Attendance\n",
    "\n",
    "Row = single attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean= (df\n",
    "    # drop null rows and cols\n",
    "    .dropna(how= 'all', axis= 'columns').dropna(how= 'all', axis= 'rows')\n",
    "    # clean col name\n",
    "    .rename(columns= module.map_col) \n",
    "    .rename(columns= lambda c: c.lower().replace(' ', '_')) \n",
    "    \n",
    "    # drop unnecessary cols\n",
    "    .drop(columns= ['class_unit'])\n",
    "    \n",
    "    # obtain current month only\n",
    "    .assign(class_date= lambda df_: module.convert_to_gmt_plus_7(df_, 'class_date'))\n",
    "    .loc[lambda df_: df_['class_date'].dt.month == module.month]\n",
    "    \n",
    "    # drop dup student attendance because i exported the att data multiple x\n",
    "    # note: assumes that one student can only exist one at a time\n",
    "    .drop_duplicates(subset= ['student_code', 'class_time', 'class_date'])\n",
    "    \n",
    "    .assign(\n",
    "        student_name= lambda df_: df_['student_name'].str.upper(),\n",
    "        # new code = name + code\n",
    "        student_code= lambda df_: (df_['student_name'] + \n",
    "                                   ' - ' + \n",
    "                                   df_['student_code'].astype('str')\n",
    "                                   ),\n",
    "        # mode = offline, online or GOC\n",
    "        class_mode= lambda df_: module.create_class_mode(df_), \n",
    "        # membership = dlx, online or GO\n",
    "        student_membership= lambda df_: module.create_student_membership(df_),\n",
    "        # clean class type for the first time\n",
    "        class_type= lambda df_: (df_['class_type']\n",
    "                                 .str.replace('Class', '', regex= False)\n",
    "                                 .str.title()\n",
    "                                 .str.strip()\n",
    "                                 .astype('category')\n",
    "                                ),  \n",
    "        # clean student center\n",
    "        student_center= lambda df_: (df_['student_center']\n",
    "                                     .str.replace('IN: ', '', regex= False)\n",
    "                                     .str.strip()\n",
    "                                     .astype('category')\n",
    "                                    ),\n",
    "        # create class time if not exist\n",
    "        class_time= lambda df_: module.create_class_time(df_),\n",
    "        # clean class description\n",
    "        class_description= lambda df_:  (df_['class_description']\n",
    "                                         .str.lower()\n",
    "                                         .str.strip()\n",
    "                                         .astype('str')\n",
    "                                        ),\n",
    "        # clean teacher name for some teachers that are duplicated in coco\n",
    "        teacher= lambda df_: module.clean_teacher_name(df_).astype('str'),\n",
    "        # create class duration if not exist\n",
    "        class_duration= lambda df_: module.create_duration(df_).astype('float'),\n",
    "        # whether the student attend or not\n",
    "        student_attendance= lambda df_: module.create_attend(df_),\n",
    "        # create class location from class description\n",
    "        class_location= lambda df_: (module\n",
    "                                     .create_class_location_1(df_)\n",
    "                                     .fillna('Online')\n",
    "                                    )\n",
    "    )\n",
    "    # note: may 2023 - replace class with shared account with its real ET\n",
    "    # this is because of shared account problem\n",
    "    # should be before merging with df_teacher\n",
    "    .assign(teacher= lambda df_: module.clean_shared_account_et(df_))\n",
    "\n",
    "    # merge with df_teacher\n",
    "    .merge(right= module.load_df_teacher(), on= 'teacher', how= 'left')\n",
    "\n",
    "    # note: class location 2nd time to get class_location from teacher center\n",
    "    .assign(class_location= lambda df_: module.create_class_location_2(df_),)\n",
    "    # assert that online class location is online\n",
    "    # assign area to each class\n",
    "    .assign(\n",
    "        class_location= lambda df_: module.assert_class_location_online(df_),\n",
    "        class_area= lambda df_: module.create_class_location_area(df_),\n",
    "    )\n",
    "    \n",
    "    # drop unnecessary columns and sort\n",
    "    .drop(columns= ['student_name', 'student_result'])\n",
    "    .sort_values(['class_date', 'class_time', 'student_code'])\n",
    "    .sort_index(axis= 1) # sort columns alphabetically\n",
    "    .reset_index(drop= True)\n",
    "    .assign(index= lambda df_: df_.index + 1) # create index column\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check assumptions\n",
    "\n",
    "# ! assert that class location match with area and mode\n",
    "assert (\n",
    "    df_clean.loc[df_clean[\"class_location\"] == \"Online\", \"class_area\"].unique()\n",
    "    == \"Online\"\n",
    ").all()\n",
    "\n",
    "for center, area in zip(\n",
    "    [module.jkt_1, module.jkt_2, module.jkt_3, module.bdg, module.sby],\n",
    "    [\"JKT 1\", \"JKT 2\", \"JKT 3\", \"BDG\", \"SBY\"],\n",
    "):\n",
    "    assert (\n",
    "        df_clean.loc[df_clean[\"class_location\"].isin(center), \"class_area\"].unique()\n",
    "        == area\n",
    "    ).all()\n",
    "\n",
    "\n",
    "# ! assert that teacher center and teacher area match\n",
    "for center, area in zip(\n",
    "    [module.jkt_1, module.jkt_2, module.jkt_3, module.bdg, module.sby],\n",
    "    [\"JKT 1\", \"JKT 2\", \"JKT 3\", \"BDG\", \"SBY\"],\n",
    "):\n",
    "    assert (\n",
    "        df_clean.loc[df_clean[\"teacher_center\"].isin(center), \"teacher_area\"].unique()\n",
    "        == area\n",
    "    ).all()\n",
    "\n",
    "\n",
    "# ! assert that no class time is missing\n",
    "assert len(df_clean.loc[df_clean[\"class_time\"].isna()]) == 0\n",
    "\n",
    "# ! assert that all online class location is online\n",
    "filter_ = df_clean[\"class_type\"].str.contains(\"Online\")\n",
    "assert (df_clean.loc[filter_, \"class_location\"] != \"Online\").sum() == 0\n",
    "\n",
    "\n",
    "# ! check if all ET in shared account is mapped\n",
    "teacher_contains_online = df[\"Teacher\"].str.lower().str.contains(\"online\")\n",
    "lower_than_eq_20 = df[\"Teacher\"].str.extract(\"(\\d+)\")[0].astype(float) <= 20\n",
    "\n",
    "list_et_shared = (\n",
    "    df.loc[(teacher_contains_online & lower_than_eq_20), \"Description\"]\n",
    "    .str.split(\"-\")\n",
    "    .str[-1]\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .unique()\n",
    ")\n",
    "\n",
    "map_et_shared = module.shared_acc_et_map.keys()\n",
    "\n",
    "unmapped = []\n",
    "for et in list_et_shared:\n",
    "    if et not in map_et_shared:\n",
    "        print(et)\n",
    "        unmapped.append(et)\n",
    "\n",
    "if len(unmapped) > 0:\n",
    "    raise Exception(\"Some ET in shared accouns are unmapped.\")\n",
    "\n",
    "\n",
    "# ! assert that no teacher has center area position == 'Shared Coount'\n",
    "mask = (\n",
    "    (\n",
    "        df_clean[[\"teacher_center\", \"teacher_area\", \"teacher_position\"]]\n",
    "        == \"Shared Account\"\n",
    "    )\n",
    "    .astype(float)\n",
    "    .sum(axis=1)\n",
    "    .astype(bool)\n",
    ")\n",
    "shared_acc = df_clean[mask]\n",
    "\n",
    "if len(shared_acc) > 0:\n",
    "    for teacher in shared_acc[\"teacher\"]:\n",
    "        print(teacher)\n",
    "    raise Exception(\"Some teachers have center/area/position == Shared Account.\")\n",
    "\n",
    "\n",
    "# ! assert GOC is classified as GOC\n",
    "if \"Global Online Center\" in df_clean[\"student_center\"].unique():\n",
    "    assert (\n",
    "        df_clean.loc[\n",
    "            df_clean[\"student_center\"] == \"Global Online Center\", \"class_mode\"\n",
    "        ].unique()\n",
    "        == \"GOC\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ! assert that no teacher is unregistered to center\n",
    "unmapped = []\n",
    "for et in df_clean.loc[df_clean[\"teacher_center\"].isna(), \"teacher\"].unique():\n",
    "    if \"online\" in et.lower():\n",
    "        continue\n",
    "    print(et)\n",
    "    unmapped.append(et)\n",
    "\n",
    "if len(unmapped) > 0:\n",
    "    raise Exception(\"Some GOC ET are unmapped.\")\n",
    "\n",
    "\n",
    "# ! assert that no teacher pos is unmapped\n",
    "teacher_pos_na = df_clean[\"teacher_position\"].isna()\n",
    "list_techer_pos_na = df_clean.loc[(teacher_pos_na), \"teacher\"].unique()\n",
    "\n",
    "if len(list_techer_pos_na) > 0:\n",
    "    for teacher in list_techer_pos_na:\n",
    "        print(teacher)\n",
    "    raise Exception(\"Some teachers have null position.\")\n",
    "\n",
    "\n",
    "# ! assert that all student membership is mapped\n",
    "assert sorted(df_clean[\"student_membership\"].unique()) == [\"Deluxe\", \"GO\", \"VIP\"]\n",
    "\n",
    "# ! sample class description and location\n",
    "# (df_clean\n",
    "#     .loc[df_clean['class_mode'] == 'Offline', ['class_description', 'class_location']]\n",
    "#     .sample(10)\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DF Session\n",
    "\n",
    "Row = single session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_85123/3067896675.py:7: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_.groupby([\"teacher\", \"class_date\", \"class_time\", \"class_type\"])[\n",
      "/tmp/ipykernel_85123/3067896675.py:12: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  df_.groupby([\"teacher\", \"class_date\", \"class_time\", \"class_type\"])[\n"
     ]
    }
   ],
   "source": [
    "df_session = (df_clean\n",
    "    .sort_values([\"teacher\", \"class_date\", \"class_time\", \"student_membership\"])\n",
    "    .assign(\n",
    "        # transform attendance\n",
    "        # assumes that one teacher can only teach one class at a time\n",
    "        student_attendance_grouped=lambda df_: (\n",
    "            df_.groupby([\"teacher\", \"class_date\", \"class_time\", \"class_type\"])[\n",
    "                \"student_attendance\"\n",
    "            ].transform(lambda x: \", \".join(x))\n",
    "        ),\n",
    "        student_membership_grouped=lambda df_: (\n",
    "            df_.groupby([\"teacher\", \"class_date\", \"class_time\", \"class_type\"])[\n",
    "                \"student_membership\"\n",
    "            ].transform(lambda x: \", \".join(x))\n",
    "        ),\n",
    "    )\n",
    "    # ! drop column unique to student and drop duplicate\n",
    "    .drop(\n",
    "        columns=[\n",
    "            \"student_attendance\",\n",
    "            \"student_center\",\n",
    "            \"student_code\",\n",
    "            \"student_membership\",\n",
    "            \"index\",\n",
    "        ]\n",
    "    )\n",
    "    .drop_duplicates(keep=\"first\")\n",
    "    .assign(\n",
    "        # create class type grouped\n",
    "        class_type_grouped=lambda df_: module.create_class_type_grouped(df_),\n",
    "        # create class service\n",
    "        class_service=lambda df_: module.create_class_service(df_),\n",
    "        # the number of people who books this class\n",
    "        class_booking=lambda df_: module.create_class_booking(df_),\n",
    "        # the number of people who actually attend\n",
    "        class_attendance=lambda df_: module.create_class_attendance(df_),\n",
    "        # delivered or not delivered\n",
    "        class_status=lambda df_: module.create_class_status(df_),\n",
    "    )\n",
    "    # drop unused cols and arrange\n",
    "    .drop(columns=[\"student_attendance_grouped\", \"student_membership_grouped\"])\n",
    "    .sort_index(axis=1)\n",
    "    .reset_index(drop=True)\n",
    "    .assign(index=lambda df_: df_.index + 1)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check assumptions\n",
    "\n",
    "# ! assert all online class is online in location\n",
    "filter_ = df_session[\"class_type\"].str.contains(\"Online\") | df_session[\"class_type_grouped\"].str.contains(\"Online\")\n",
    "assert (df_session.loc[filter_, \"class_location\"] != \"Online\").sum() == 0\n",
    "\n",
    "\n",
    "# ! booking >= attendance -> should return 0\n",
    "assert (df_session['class_booking'] < df_session['class_attendance']).sum() == 0\n",
    "\n",
    "\n",
    "# ! vip chould only have 3 class type (one-on-one, VPG, other)\n",
    "vips= [\n",
    "    # 'GOC',\n",
    "    'One-on-one',\n",
    "    'Online One-on-one',\n",
    "    'Online VPG',\n",
    "    'VPG']\n",
    "\n",
    "# print(sorted(df_session\n",
    "#     .loc[\n",
    "#         df_session['class_service'] == 'VIP', 'class_type_grouped'\n",
    "#     ]\n",
    "#     .unique()\n",
    "# ))\n",
    "\n",
    "assert sorted((df_session.loc[df_session['class_service'] == 'VIP', 'class_type_grouped']).unique()) == vips\n",
    "\n",
    "\n",
    "# ! assert all class service are mapped\n",
    "assert sorted(df_session['class_service'].unique()) == ['Deluxe', 'Deluxe & Go', 'VIP']\n",
    "\n",
    "\n",
    "# ! vip one on one should be booked only by 1 person\n",
    "# (df_session\n",
    "#     .loc[(df_session['class_type_grouped'].str.contains('One-on-one')), 'class_booking']\n",
    "#     .value_counts()\n",
    "# )\n",
    "# (df_session\n",
    "#     .loc[\n",
    "#         (df_session['class_type_grouped'].str.contains('One-on-one')) &\\\n",
    "#         (df_session['class_booking'] > 1) \n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# ! match class_type with class_type_grouped\n",
    "# (df_session\n",
    "#     .groupby(['class_service', 'class_type', 'class_type_grouped'])\n",
    "#     .agg(count= ('class_type_grouped', 'count'))\n",
    "#     .loc[lambda df_: df_['count'] > 0]\n",
    "# )\n",
    "\n",
    "\n",
    "# ! sample class description\n",
    "# df_session.loc[:, ['class_description', 'class_service', 'class_location', 'class_type', 'class_type_grouped']].sample(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save DF"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_clean usually 19000-22000 rows long\n",
    "df_session usually 3300-3600 rows long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "session = 4962\n",
      "attendance = 21196\n",
      "\n",
      "class_status\n",
      "Given        4337\n",
      "Not Given     625\n",
      "Name: count, dtype: int64\n",
      "87.0\n"
     ]
    }
   ],
   "source": [
    "print(f'session = {len(df_session)}')\n",
    "print(f'attendance = {len(df_clean)}\\n')\n",
    "\n",
    "# ! class status value counts\n",
    "status= (df_session['class_status'].value_counts())\n",
    "print(status)\n",
    "print((status['Given'] / status.sum() * 100).round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nov 2023'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range=\\\n",
    "    df_clean['class_date'].min().month_name()[:3] +\\\n",
    "    ' ' + str(df_clean['class_date'].min().year)\n",
    "date_range= date_range.lower()\n",
    "date_range"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/11 nov 2023/data session nov 2023.xlsx')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file= df_session\n",
    "folder= config.path\n",
    "filename= 'data session ' + date_range + '.xlsx'\n",
    "\n",
    "filepath= folder / filename\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exist.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(filepath):\n",
    "    file.to_excel(filepath, engine='xlsxwriter', index= False)\n",
    "    print('File saved.')\n",
    "else:\n",
    "    print('File already exist.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('data/11 nov 2023/data attendance nov 2023.xlsx')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file= df_clean\n",
    "folder= config.path\n",
    "filename= 'data attendance ' + date_range + '.xlsx'\n",
    "\n",
    "filepath= folder / filename\n",
    "filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exist.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(filepath):\n",
    "    file.to_excel(filepath, engine='xlsxwriter', index= False)\n",
    "    print('File saved.')\n",
    "else:\n",
    "    print('File already exist.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc_list= list(df_ori.loc[(df_ori['Description'].str.contains('at', regex= False, na= False)), 'Description'].unique())\n",
    "# for i in desc_list:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_session\n",
    "#     .loc[df_session['class_service'] == 'VIP']\n",
    "#     .groupby(['class_type_grouped', 'class_type'])\n",
    "#     .agg(count= ('class_type', 'size'))\n",
    "#     .reset_index()\n",
    "#     .pivot(index= 'class_type', columns= 'class_type_grouped')\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (df_session\n",
    "#     .loc[df_session['class_service'] == 'VIP', 'class_type']\n",
    "#     .unique()\n",
    "#     .to_list()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean['class_type'].unique().to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check why is there duration 0\n",
    "# df_ori['Duration'].value_counts(dropna= False)\n",
    "# df.loc[df['Description'].str.lower() == 'advising session - altysa @go']\n",
    "# df_clean.loc[df_clean['class_duration'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GOC class\n",
    "# df.loc[df['Teacher'] == 'D. Sughraa']\n",
    "# df_clean.loc[df_clean['teacher'] == 'D. Sughraa']\n",
    "# df_clean['teacher'].sample(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "online trainer 1-20 = inhouse ET\n",
    "\n",
    "online trainer 21-30 = ooolab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_shared_account_et(df: pd.DataFrame):\n",
    "    \n",
    "#     et_map= {   \n",
    "#         'anna': 'Tinggogoy Anna Maria',\n",
    "#         'ruth olivia': 'Pakpahan Ruth Olivia Angelina',\n",
    "#         'daniel': 'Bradshaw Daniel',\n",
    "#         'derek': 'Laurendeau Derek',\n",
    "#         'imelda': 'Basuki Imelda',\n",
    "#         'vivi': 'Hazisyah Alifia Nur',\n",
    "#         'priscill': 'Priscilla Yokhebed',\n",
    "#         'ryan b': 'Blasczyk Ryan',\n",
    "#         'eka': 'Mustikawati Eka',\n",
    "#         'rahul': 'Azhar Rahul Finaya',\n",
    "#         'ade': 'Setiadi Sapto',\n",
    "#         'oliv': 'Pakpahan Ruth Olivia Angelina',\n",
    "#         'uzli': 'Ainiyah Uzlifatul',\n",
    "#         'john lawrence': 'Lawrence Moore John',\n",
    "#         'toby': 'Phillips Toby',\n",
    "#         'risma': 'Handayani Khaerunisyah Risma',\n",
    "#         'nadya': 'Nasarah Nadya',\n",
    "#         'fairuz': 'Fairuz Muhammad',\n",
    "#         'aurora': 'Rifani Aurora Nurhidayah',\n",
    "#         'tri bekti': 'Hundoyo Tri Bekti',\n",
    "#         'madeline': 'Jane Quinn Madeline',\n",
    "#         'medi': 'Medianti Annisa',\n",
    "#         'jason': 'Gereau Jason Jarett',\n",
    "#         'priscilla': 'Priscilla Yokhebed',\n",
    "#         'nova': 'Rahmadya Nova Ayu',\n",
    "#         'jack jones': 'Jones Jack William Isaac',\n",
    "#         'priscil': 'Priscilla Yokhebed',\n",
    "#         'olive': 'Pakpahan Ruth Olivia Angelina',\n",
    "#         'prettya': 'Kartikasari Prettya Nur',\n",
    "#         'alex': 'Algar Sinclair Alexander John',\n",
    "#         'shafira': 'Ayuningtyas Shafira',\n",
    "#         'anggi': 'Ansyahputri Anggita Rizkiarachma',\n",
    "#         'ryan': 'Blasczyk Ryan'\n",
    "#     }\n",
    "\n",
    "#     contains_online= (df['teacher'].str.contains('Online'))\n",
    "#     more_than_20= (df['teacher'].str.extract('(\\d+)')[0].astype(float) > 20)\n",
    "#     lower_than_eq_20= (df['teacher'].str.extract('(\\d+)')[0].astype(float) <= 20)\n",
    "\n",
    "#     conditions= [\n",
    "#         (contains_online & lower_than_eq_20),\n",
    "#     ]\n",
    "#     choices= [\n",
    "#         (df\n",
    "#             ['class_description']\n",
    "#             .str.split('-').str[-1].str.strip()\n",
    "#             .map(et_map)\n",
    "#         ),\n",
    "#     ]\n",
    "#     return np.select(conditions, choices, default= df['teacher'])\n",
    "\n",
    "# df_clean.assign(teacher= lambda df_: clean_shared_account_et(df_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shared account class type\n",
    "\n",
    "# df_session.loc[\n",
    "#     df_session['class_description'].str.contains(' - priscill'),\n",
    "#     ['class_service', 'class_description', 'class_type', 'class_type_grouped', 'teacher']\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check comunity class\n",
    "# (df_session\n",
    "#     .loc[df_session['class_type_grouped'] == 'Offline Community']\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check class session\n",
    "# df_session.groupby(['class_type', 'class_type_grouped']).size().to_frame().reset_index().loc[lambda df_: df_[0] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find community class\n",
    "# (df_session\n",
    "#     .loc[df_session['class_type'].isin(['Social Club', 'Online Social Club'])]\n",
    "#     .loc[df_session['class_description'].str.contains('community'),'class_description']\n",
    "#     .unique()\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[(df['Description'].str.contains('FDN OFFLINE @SMB', na= False)) & (df['Teacher'] == 'BLASCZYK (SMB) RYAN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean.loc[df_clean['teacher'].str.contains('Bushey'), 'teacher'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f3a8bfdb5a557fdd89d56033d82eaae78056dbe7820aa28ba41c9c92a7a71aee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
